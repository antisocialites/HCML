{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebdf6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from fairlearn.datasets import fetch_acs_income\n",
    "import shap\n",
    "\n",
    "from scipy.spatial.distance import cosine, euclidean\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, ParameterSampler, train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import OneHotEncoder, TargetEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, classification_report,  roc_auc_score\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from xgboost import XGBRegressor, XGBClassifier #continuous values?\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import levene\n",
    "from scipy.stats import ttest_ind\n",
    "import joblib\n",
    "\n",
    "# Construct the dataset\n",
    "\n",
    "def preprocess_income_data(df, threshold):\n",
    "    df_copy = df.copy()\n",
    "    df_copy['binary_target'] = (df_copy['target'] >= threshold).astype(int)\n",
    "    X = df_copy.drop(columns=['target', 'binary_target'], errors='ignore')\n",
    "    y = df_copy['binary_target']\n",
    "    return X, y\n",
    "\n",
    "data = fetch_acs_income()\n",
    "# convert to df\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    " # I'm not sure what this feature even is cause I can't  find anything about it in the documenation so I'm leaving it oout for now\n",
    "df = df.drop(columns=['ST'], errors='ignore')\n",
    "\n",
    "numeric_cols = ['AGEP', 'WKHP']\n",
    "categorical_cols = ['COW', 'SCHL', 'MAR', 'OCCP', 'POBP', 'RELP', 'SEX',  'RAC1P'] \n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=True), categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "threshold = 50000\n",
    "X, y = preprocess_income_data(df, threshold)\n",
    "\n",
    "# tempsplit: train (70%) and temp (30%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# final split: validation (15%) and test (15%) from temp\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "006da8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the SHAP-values\n",
    "\n",
    "#file_path = 'deepshap_values_health.pkl'\n",
    "\n",
    "#with open(file_path, 'rb') as file:\n",
    "#    shap_values = pickle.load(file)\n",
    "# ----------------------------------------------\n",
    "shap_values = (np.load(\"deepshap_values_income.npy\"))\n",
    "# ----------------------------------------------\n",
    "#shap_values = joblib.load(\"deepshap_explainer_income.joblib\", mmap_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f4dc6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m mask_A \u001b[38;5;241m=\u001b[39m (X_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEX\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m (X_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRAC1P\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m mask_B \u001b[38;5;241m=\u001b[39m (X_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEX\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m&\u001b[39m (X_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRAC1P\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m shap_male \u001b[38;5;241m=\u001b[39m \u001b[43mshap_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m[mask_A\u001b[38;5;241m.\u001b[39mvalues]\n\u001b[0;32m      6\u001b[0m shap_female \u001b[38;5;241m=\u001b[39m shap_values\u001b[38;5;241m.\u001b[39mvalues[mask_B\u001b[38;5;241m.\u001b[39mvalues]\n\u001b[0;32m      7\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOW_1.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOW_2.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOW_3.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOW_4.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOW_5.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOW_6.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOW_7.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOW_8.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHL_1.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHL_2.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHL_3.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHL_4.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHL_5.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHL_6.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHL_7.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHL_8.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHL_9.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHL_10.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHL_11.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHL_12.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHL_13.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHL_14.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHL_15.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHL_16.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHL_17.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHL_18.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHL_19.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHL_20.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHL_21.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHL_22.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHL_23.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHL_24.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAR_1.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAR_2.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAR_3.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAR_4.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAR_5.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRELP_0.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRELP_1.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRELP_2.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRELP_3.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRELP_4.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRELP_5.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRELP_6.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRELP_7.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRELP_8.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRELP_9.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRELP_10.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRELP_11.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRELP_12.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRELP_13.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRELP_14.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRELP_15.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRELP_16.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRELP_17.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEX_1.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEX_2.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRAC1P_1.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRAC1P_2.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRAC1P_3.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRAC1P_4.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRAC1P_5.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRAC1P_6.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRAC1P_7.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRAC1P_8.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRAC1P_9.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAGEP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWKHP\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "# example: male v female cauacasian\n",
    "mask_A = (X_test['SEX'] == 1) & (X_test['RAC1P'] == 1)\n",
    "mask_B = (X_test['SEX'] == 2) & (X_test['RAC1P'] == 1)\n",
    "\n",
    "shap_male = shap_values.values[mask_A.values]\n",
    "shap_female = shap_values.values[mask_B.values]\n",
    "feature_names = ['COW_1.0', 'COW_2.0', 'COW_3.0', 'COW_4.0', 'COW_5.0', 'COW_6.0', 'COW_7.0', 'COW_8.0', 'SCHL_1.0', 'SCHL_2.0', 'SCHL_3.0', 'SCHL_4.0', 'SCHL_5.0', 'SCHL_6.0', 'SCHL_7.0', 'SCHL_8.0', 'SCHL_9.0', 'SCHL_10.0', 'SCHL_11.0', 'SCHL_12.0', 'SCHL_13.0', 'SCHL_14.0', 'SCHL_15.0', 'SCHL_16.0', 'SCHL_17.0', 'SCHL_18.0', 'SCHL_19.0', 'SCHL_20.0', 'SCHL_21.0', 'SCHL_22.0', 'SCHL_23.0', 'SCHL_24.0', 'MAR_1.0', 'MAR_2.0', 'MAR_3.0', 'MAR_4.0', 'MAR_5.0', 'RELP_0.0', 'RELP_1.0', 'RELP_2.0', 'RELP_3.0', 'RELP_4.0', 'RELP_5.0', 'RELP_6.0', 'RELP_7.0', 'RELP_8.0', 'RELP_9.0', 'RELP_10.0', 'RELP_11.0', 'RELP_12.0', 'RELP_13.0', 'RELP_14.0', 'RELP_15.0', 'RELP_16.0', 'RELP_17.0', 'SEX_1.0', 'SEX_2.0', 'RAC1P_1.0', 'RAC1P_2.0', 'RAC1P_3.0', 'RAC1P_4.0', 'RAC1P_5.0', 'RAC1P_6.0', 'RAC1P_7.0', 'RAC1P_8.0', 'RAC1P_9.0', 'AGEP', 'WKHP']\n",
    "\n",
    "shapiro_list = []\n",
    "shapiro_listW = []\n",
    "levenes = []\n",
    "z_list = []\n",
    "t_test = []\n",
    "print(len(feature_names))\n",
    "\n",
    "normality_warnings = 0\n",
    "varience_warnings = 0\n",
    "\n",
    "for i, feature in enumerate(feature_names):\n",
    "    group1 = shap_male[:, i]\n",
    "    group2 = shap_female[:, i]\n",
    "    \n",
    "    # randomly sample 5000 instances of both groups\n",
    "    try:\n",
    "        group1 = np.random.choice(group1, size=5000, replace=False)\n",
    "        group2 = np.random.choice(group2, size=5000, replace=False)\n",
    "    except:\n",
    "        pass # array is already less than 5000\n",
    "\n",
    "    # normalise:\n",
    "    '''\n",
    "    group1 = preprocessing.normalize([group1], norm='l2')\n",
    "    group2 = preprocessing.normalize([group2], norm='l2')\n",
    "    '''\n",
    "    # Shapiro-Wilk test\n",
    "    shapiro_gr1 = shapiro(group1).pvalue\n",
    "    shapiro_gr2 = shapiro(group2).pvalue\n",
    "    shapiroW_gr1 = shapiro(group1).statistic\n",
    "    shapiroW_gr2 = shapiro(group2).statistic\n",
    "    shapiro_list.append([shapiro_gr1, shapiro_gr2])\n",
    "    shapiro_listW.append([shapiroW_gr1, shapiroW_gr2])\n",
    "\n",
    "    # Levenes test ---> depends on assumption of normality!\n",
    "    w_stats, p_value = levene(group1, group2, center='mean')\n",
    "    levenes.append([w_stats, p_value])\n",
    "\n",
    "    # outlier test ---> depends on assumption of normality!\n",
    "    z1 = np.abs(stats.zscore(group1))\n",
    "    z2 = np.abs(stats.zscore(group2))\n",
    "    z_list.append([z1, z2])\n",
    "\n",
    "    stat, pval = ttest_ind(group1, group2, equal_var=False)  # Welch's t-test to account for variance differences\n",
    "    t_test.append([stat,pval])\n",
    "\n",
    "print(\"Shapiro values: \", shapiro_list)\n",
    "print(\"Shapiro statistic: \", shapiro_listW)\n",
    "print(\"Levens values: \", levenes)\n",
    "print(\"z-scores that deviate: \", z_list)\n",
    "print(\"t-test  values: \",t_test)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "for i, feature in enumerate(feature_names):\n",
    "    group1 = shap_male[:, i+1]\n",
    "    group2 = shap_female[:, i+1]\n",
    "\n",
    "    plt.hist(group1, bins=30, color='skyblue', edgecolor='black')\n",
    "\n",
    "    plt.show()\n",
    "    plt.hist(group2, bins=30, color='skyblue', edgecolor='black')\n",
    "\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b74030",
   "metadata": {},
   "source": [
    "Statistical to-do:\n",
    "1) L2 - normalize all SHAP vectors to be used\n",
    "2) Apply Shapiro-Wilk test on a sample of N = 5000 to check for normality\n",
    "3) Independent t-test / non-parametric test regardless of small p-values\n",
    "4) effect size (threshold of D <= 0.2)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
